{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import uuid\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from typing import List\n",
    "import nbformat as nbf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54c7cab3</th>\n",
       "      <td>code</td>\n",
       "      <td>%reset -f \\n\\nif 1:\\n    # https://www.kaggle....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe66203e</th>\n",
       "      <td>code</td>\n",
       "      <td>#config \\n\\ndiscourse_marker_to_label = {\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844d5f8</th>\n",
       "      <td>code</td>\n",
       "      <td>#data\\n\\ndf_text=[]\\nfor id in valid_id:\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5ce8863c</th>\n",
       "      <td>code</td>\n",
       "      <td>#net\\n\\nfrom bigbird_base_model import Net as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a0777c4</th>\n",
       "      <td>code</td>\n",
       "      <td>#processing\\n\\ndef text_to_word(text):\\n    wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703bb6d</th>\n",
       "      <td>code</td>\n",
       "      <td>## main submission function !!!!\\n\\n\\ndef run_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a32c095</th>\n",
       "      <td>code</td>\n",
       "      <td>#check function\\ndef run_check_dataset():\\n\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865ad516</th>\n",
       "      <td>code</td>\n",
       "      <td># '''\\n# cross validation results \\n# WITHOUT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02a0be6d</th>\n",
       "      <td>code</td>\n",
       "      <td>#run_check_dataset()\\nrun_submit()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7f270e34</th>\n",
       "      <td>markdown</td>\n",
       "      <td>This notebook illustrate how to speedup infere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                             source\n",
       "54c7cab3      code  %reset -f \\n\\nif 1:\\n    # https://www.kaggle....\n",
       "fe66203e      code  #config \\n\\ndiscourse_marker_to_label = {\\n   ...\n",
       "7844d5f8      code  #data\\n\\ndf_text=[]\\nfor id in valid_id:\\n    ...\n",
       "5ce8863c      code  #net\\n\\nfrom bigbird_base_model import Net as ...\n",
       "4a0777c4      code  #processing\\n\\ndef text_to_word(text):\\n    wo...\n",
       "4703bb6d      code  ## main submission function !!!!\\n\\n\\ndef run_...\n",
       "4a32c095      code  #check function\\ndef run_check_dataset():\\n\\n ...\n",
       "865ad516      code  # '''\\n# cross validation results \\n# WITHOUT ...\n",
       "02a0be6d      code                 #run_check_dataset()\\nrun_submit()\n",
       "7f270e34  markdown  This notebook illustrate how to speedup infere..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../raw_data/AI4Code/test_data/0010483c12ba9b.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilhanb11/code/ste94000/google_ai4_code/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/home/ilhanb11/code/ste94000/google_ai4_code/notebooks/newntk.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_notebook(df: pd.DataFrame, output_path: str):\n",
    "    # Create a new notebook object\n",
    "    nb = nbf.v4.new_notebook()\n",
    "\n",
    "    # Iterate over DataFrame rows and create cells\n",
    "    cells = []\n",
    "    for index, row in df.iterrows():\n",
    "        cell_type = row['cell_type']\n",
    "        source = row['source']\n",
    "\n",
    "        if cell_type == 'markdown':\n",
    "            cell = nbf.v4.new_markdown_cell(source)\n",
    "        elif cell_type == 'code':\n",
    "            cell = nbf.v4.new_code_cell(source)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported cell type: {cell_type}\")\n",
    "\n",
    "        cells.append(cell)\n",
    "\n",
    "    # Assign cells to the notebook\n",
    "    nb['cells'] = cells\n",
    "\n",
    "    # Write the notebook to a file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        nbf.write(nb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_to_notebook(df, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path='../notebooks/test_notebook.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cell_id():\n",
    "    return uuid.uuid4().hex[:8]\n",
    "\n",
    "def convert_notebook(notebook_path: str) -> pd.DataFrame:\n",
    "\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as file:\n",
    "        notebook_json = json.load(file)\n",
    "\n",
    "    cells = notebook_json['cells']\n",
    "    data = []\n",
    "    for cell in cells:\n",
    "        cell_type = cell['cell_type']\n",
    "        source = ''.join(cell['source'])  # Join list of strings into a single string\n",
    "        cell_id = generate_cell_id()\n",
    "        data.append({'cell_id': cell_id, 'cell_type': cell_type, 'source': source})\n",
    "\n",
    "    return(pd.DataFrame(data).assign(id=os.path.basename(notebook_path).split(\".\")[0]).set_index('cell_id'))\n",
    "\n",
    "def clean_code(cell: str) -> str:\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells: List[str], n: int) -> List[str]:\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return cells\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "def get_features(df: pd.DataFrame) -> dict:\n",
    "    features = {}\n",
    "    for i, sub_df in tqdm(df.groupby(\"id\"), desc=\"Features\"):\n",
    "        features[i] = {}\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[i][\"total_code\"] = total_code\n",
    "        features[i][\"total_md\"] = total_md\n",
    "        features[i][\"codes\"] = codes\n",
    "    return features\n",
    "\n",
    "\n",
    "def tokenize(df: pd.DataFrame, fts: dict) -> dict:\n",
    "    input_ids = np.zeros((len(df), TOTAL_MAX_LEN), dtype=np.int32)\n",
    "    attention_mask = np.zeros((len(df), TOTAL_MAX_LEN), dtype=np.int32)\n",
    "    features = np.zeros((len(df),), dtype=np.float32)\n",
    "\n",
    "    for i, row in tqdm(\n",
    "        df.reset_index(drop=True).iterrows(), desc=\"Tokens\", total=len(df)\n",
    "    ):\n",
    "        row_fts = fts[row.id]\n",
    "\n",
    "        inputs = TOKENIZER.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MD_MAX_LEN,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        code_inputs = TOKENIZER.batch_encode_plus(\n",
    "            [str(x) for x in row_fts[\"codes\"]] or [\"\"],\n",
    "            add_special_tokens=True,\n",
    "            max_length=23,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        for x in code_inputs[\"input_ids\"]:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:TOTAL_MAX_LEN]\n",
    "        if len(ids) != TOTAL_MAX_LEN:\n",
    "            ids = ids + [\n",
    "                TOKENIZER.pad_token_id,\n",
    "            ] * (TOTAL_MAX_LEN - len(ids))\n",
    "\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        for x in code_inputs[\"attention_mask\"]:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:TOTAL_MAX_LEN]\n",
    "        if len(mask) != TOTAL_MAX_LEN:\n",
    "            mask = mask + [\n",
    "                TOKENIZER.pad_token_id,\n",
    "            ] * (TOTAL_MAX_LEN - len(mask))\n",
    "\n",
    "        input_ids[i] = ids\n",
    "        attention_mask[i] = mask\n",
    "        features[i] = (\n",
    "            row_fts[\"total_md\"] / (row_fts[\"total_md\"] + row_fts[\"total_code\"]) or 1\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"features\": features,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a8a43ede</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nimpor...</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d474e2a</th>\n",
       "      <td>code</td>\n",
       "      <td>def read_notebook(path: str) -&gt; pd.DataFrame:\\...</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d90ef310</th>\n",
       "      <td>markdown</td>\n",
       "      <td># test test test afhjehfjeanfjenfnezfjkenf</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc46914f</th>\n",
       "      <td>markdown</td>\n",
       "      <td></td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78bcb222</th>\n",
       "      <td>code</td>\n",
       "      <td>def get_dataset(\\n    input_ids: np.array,\\n  ...</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7780f4be</th>\n",
       "      <td>markdown</td>\n",
       "      <td>fehflezhfkezflkznelkfnzelkfnzeklfn</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79392ebf</th>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('../raw_data/train_ancestors....</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e2253470</th>\n",
       "      <td>markdown</td>\n",
       "      <td>jefkezjfkzejfkzejfkjzefkjzekfjzekfj</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9213eaac</th>\n",
       "      <td>markdown</td>\n",
       "      <td>fuck off!</td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cff2780f</th>\n",
       "      <td>markdown</td>\n",
       "      <td></td>\n",
       "      <td>test_notebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                             source  \\\n",
       "cell_id                                                                 \n",
       "a8a43ede      code  import pandas as pd\\nimport numpy as np\\nimpor...   \n",
       "3d474e2a      code  def read_notebook(path: str) -> pd.DataFrame:\\...   \n",
       "d90ef310  markdown         # test test test afhjehfjeanfjenfnezfjkenf   \n",
       "dc46914f  markdown                                                      \n",
       "78bcb222      code  def get_dataset(\\n    input_ids: np.array,\\n  ...   \n",
       "7780f4be  markdown                 fehflezhfkezflkznelkfnzelkfnzeklfn   \n",
       "79392ebf      code  df = pd.read_csv('../raw_data/train_ancestors....   \n",
       "e2253470  markdown                jefkezjfkzejfkzejfkjzefkjzekfjzekfj   \n",
       "9213eaac  markdown                                          fuck off!   \n",
       "cff2780f  markdown                                                      \n",
       "\n",
       "                     id  \n",
       "cell_id                  \n",
       "a8a43ede  test_notebook  \n",
       "3d474e2a  test_notebook  \n",
       "d90ef310  test_notebook  \n",
       "dc46914f  test_notebook  \n",
       "78bcb222  test_notebook  \n",
       "7780f4be  test_notebook  \n",
       "79392ebf  test_notebook  \n",
       "e2253470  test_notebook  \n",
       "9213eaac  test_notebook  \n",
       "cff2780f  test_notebook  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = convert_notebook(notebook_path=notebook_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175a004a330247738b5c61ab31d7b42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Features:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_notebook': {'total_code': 4,\n",
       "  'total_md': 6,\n",
       "  'codes': ['import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns',\n",
       "   'def read_notebook(path: str) -> pd.DataFrame:\\n    return (\\n        pd.read_json(path, dtype={\"cell_type\": \"category\", \"source\": \"str\"})\\n        .assign(id=os.path.basename(path).split(\".\")[0])\\n        .rename_axis(\"cell_id\")\\n    )',\n",
       "   'def get_dataset(\\n    input_ids: np.array,\\n    attention_mask: np.array,\\n    feature: np.array,\\n) -> tf.data.Dataset:\\n    dataset = tf.data.Dataset.from_tensor_slices(\\n        {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"feature\": feature}\\n    )\\n    dataset = dataset.batch(BATCH_SIZE)\\n    return dataset.prefetch(tf.data.AUTOTUNE)',\n",
       "   \"df = pd.read_csv('../raw_data/train_ancestors.csv')\\ndf.head(10)\"]}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts = get_features(df)\n",
    "fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_ai4_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
