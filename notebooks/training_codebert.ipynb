{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from IPython.display import display\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.11.0\n",
      "Using GPU/CPU\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../raw_data/AI4Code\"\n",
    "BASE_MODEL = \"../models/codebert-base\"\n",
    "N_SPLITS = 5\n",
    "SEQ_LEN = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "    BATCH_SIZE = 128 * STRATEGY.num_replicas_in_sync\n",
    "except Exception:\n",
    "    TPU = None\n",
    "    STRATEGY = tf.distribute.get_strategy()\n",
    "    BATCH_SIZE = 32\n",
    "    LIMIT = 100\n",
    "\n",
    "print(\"TensorFlow\", tf.__version__)\n",
    "\n",
    "if TPU is not None:\n",
    "    print(\"Using TPU v3-8\")\n",
    "else:\n",
    "    print(\"Using GPU/CPU\")\n",
    "\n",
    "print(\"Batch size:\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_notebook(path: str) -> pd.DataFrame:\n",
    "    with open(path) as file:\n",
    "        df = pd.DataFrame(json.load(file))\n",
    "    df[\"id\"] = os.path.splitext(os.path.basename(path))[0]\n",
    "    return df\n",
    "\n",
    "def expand_order(row: Tuple[str, str]) -> pd.DataFrame:\n",
    "    cell_ids = row[1].split(\" \")\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": [row[0] for _ in range(len(cell_ids))],\n",
    "            \"cell_id\": cell_ids,\n",
    "            \"rank\": range(len(cell_ids)),\n",
    "        }\n",
    "    )\n",
    "    df[\"pct_rank\"] = df[\"rank\"] / len(df)\n",
    "    return df\n",
    "\n",
    "def tokenize(source: pd.Series) -> Tuple[np.array, np.array]:\n",
    "    tokenizer = transformers.RobertaTokenizer.from_pretrained(BASE_MODEL, do_lower_case=True)\n",
    "\n",
    "    input_ids = np.zeros((len(source), SEQ_LEN), dtype=\"int32\")\n",
    "    attention_mask = np.zeros((len(source), SEQ_LEN), dtype=\"int32\")\n",
    "\n",
    "    for i, x in enumerate(tqdm(source, total=len(source))):\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            x,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=SEQ_LEN,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        input_ids[i] = encoding[\"input_ids\"]\n",
    "        attention_mask[i] = encoding[\"attention_mask\"]\n",
    "\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def get_dataset(\n",
    "    input_ids: np.array,\n",
    "    attention_mask: np.array,\n",
    "    labels: Optional[np.array] = None,\n",
    "    ordered: bool = False,\n",
    "    repeated: bool = False,\n",
    ") -> tf.data.Dataset:\n",
    "    if labels is not None:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ({\"input_ids\": input_ids, \"attention_mask\": attention_mask}, labels)\n",
    "        )\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "        )\n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    if not ordered:\n",
    "        dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_model() -> tf.keras.Model:\n",
    "    backbone = transformers.TFAutoModel.from_pretrained(BASE_MODEL)\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(SEQ_LEN,),\n",
    "        dtype=tf.int32,\n",
    "        name=\"input_ids\",\n",
    "    )\n",
    "    attention_mask = tf.keras.layers.Input(\n",
    "        shape=(SEQ_LEN,),\n",
    "        dtype=tf.int32,\n",
    "        name=\"attention_mask\",\n",
    "    )\n",
    "    x = backbone(\n",
    "        {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "        },\n",
    "    )\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"linear\", dtype=\"float32\")(x[0][:, 0, :])\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_ids, attention_mask],\n",
    "        outputs=outputs,\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb06e08534364f8ab99f1096a4f2d2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab144a3484241ceb206ff2c19ce0859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>a1bc6a66</td>\n",
       "      <td>Based on PCA decomposition above can be mak...</td>\n",
       "      <td>5007978dc9bc18</td>\n",
       "      <td>33</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>14c84682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>f3604143</td>\n",
       "      <td>![Autoencoder](https://upload.wikimedia.org/wi...</td>\n",
       "      <td>5007978dc9bc18</td>\n",
       "      <td>9</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>14c84682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>90ac3be7</td>\n",
       "      <td>## &lt;center&gt; Reference\\n* https://www.kaggle.co...</td>\n",
       "      <td>5007978dc9bc18</td>\n",
       "      <td>34</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>14c84682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>212bafbe</td>\n",
       "      <td>Pipeline released in this kernel is very simpl...</td>\n",
       "      <td>5007978dc9bc18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>14c84682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>9a0829ad</td>\n",
       "      <td>Explained variance ration of PCA</td>\n",
       "      <td>5007978dc9bc18</td>\n",
       "      <td>25</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>14c84682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1679 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell_id                                             source  \\\n",
       "0     58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1     950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2     3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3     99385c1e    #### How did carriers performed over the years?   \n",
       "4     26c65ce6  An average departure delay and its std are slo...   \n",
       "...        ...                                                ...   \n",
       "1811  a1bc6a66     Based on PCA decomposition above can be mak...   \n",
       "1812  f3604143  ![Autoencoder](https://upload.wikimedia.org/wi...   \n",
       "1813  90ac3be7  ## <center> Reference\\n* https://www.kaggle.co...   \n",
       "1814  212bafbe  Pipeline released in this kernel is very simpl...   \n",
       "1815  9a0829ad                   Explained variance ration of PCA   \n",
       "\n",
       "                  id  rank  pct_rank ancestor_id  \n",
       "0     2ac1be019bf73e    26  0.440678    b66b5e9a  \n",
       "1     2ac1be019bf73e    21  0.355932    b66b5e9a  \n",
       "2     2ac1be019bf73e    25  0.423729    b66b5e9a  \n",
       "3     2ac1be019bf73e    52  0.881356    b66b5e9a  \n",
       "4     2ac1be019bf73e    45  0.762712    b66b5e9a  \n",
       "...              ...   ...       ...         ...  \n",
       "1811  5007978dc9bc18    33  0.942857    14c84682  \n",
       "1812  5007978dc9bc18     9  0.257143    14c84682  \n",
       "1813  5007978dc9bc18    34  0.971429    14c84682  \n",
       "1814  5007978dc9bc18    10  0.285714    14c84682  \n",
       "1815  5007978dc9bc18    25  0.714286    14c84682  \n",
       "\n",
       "[1679 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = glob.glob(os.path.join(DATA_PATH, \"train_data\", \"*.json\"))\n",
    "if LIMIT is not None:\n",
    "    paths = paths[:LIMIT]\n",
    "\n",
    "source_df = pd.concat([read_notebook(x) for x in tqdm(paths, total=len(paths))])\n",
    "\n",
    "source_df = source_df[source_df[\"cell_type\"] == \"markdown\"]\n",
    "source_df = source_df.drop(\"cell_type\", axis=1)\n",
    "source_df = source_df.rename_axis(\"cell_id\").reset_index()\n",
    "\n",
    "order_df = pd.read_csv(os.path.join(DATA_PATH, \"train_orders.csv\"), index_col=\"id\")\n",
    "order_df = pd.concat(\n",
    "    [expand_order(row) for row in tqdm(order_df.itertuples(), total=len(order_df))]\n",
    ")\n",
    "\n",
    "ancestors_df = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"train_ancestors.csv\"),\n",
    "    usecols=[\"id\", \"ancestor_id\"],\n",
    "    index_col=\"id\",\n",
    ")\n",
    "\n",
    "df = source_df.merge(order_df, on=[\"id\", \"cell_id\"]).merge(ancestors_df, on=\"id\")\n",
    "df = df.dropna()\n",
    "\n",
    "lang_df = pd.read_csv('../raw_data/AI4Code/all_languages.csv')\n",
    "merged_df = df.merge(lang_df, on='id', how='left')\n",
    "merged_df = merged_df[merged_df['score'] >= 0.75]\n",
    "merged_df = merged_df[merged_df['language'] == 'en']\n",
    "df = merged_df.drop(columns=['language', 'score'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143005</th>\n",
       "      <td>d5e9c516</td>\n",
       "      <td># Optimization</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>36</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143006</th>\n",
       "      <td>47fd56dd</td>\n",
       "      <td># Optimizer Analytics</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>28</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143007</th>\n",
       "      <td>a3bdddf7</td>\n",
       "      <td># Define Constraints</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143008</th>\n",
       "      <td>67b26d0c</td>\n",
       "      <td>In validation RMS 99.4 and Adam 66.4 this crea...</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>46</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143009</th>\n",
       "      <td>c0bb4fbe</td>\n",
       "      <td># Loading data from file</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>4</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143010 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id                                             source  \\\n",
       "0       58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1       950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2       3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3       99385c1e    #### How did carriers performed over the years?   \n",
       "4       26c65ce6  An average departure delay and its std are slo...   \n",
       "...          ...                                                ...   \n",
       "143005  d5e9c516                                     # Optimization   \n",
       "143006  47fd56dd                              # Optimizer Analytics   \n",
       "143007  a3bdddf7                               # Define Constraints   \n",
       "143008  67b26d0c  In validation RMS 99.4 and Adam 66.4 this crea...   \n",
       "143009  c0bb4fbe                           # Loading data from file   \n",
       "\n",
       "                    id  rank  pct_rank ancestor_id  \n",
       "0       2ac1be019bf73e    26  0.440678    b66b5e9a  \n",
       "1       2ac1be019bf73e    21  0.355932    b66b5e9a  \n",
       "2       2ac1be019bf73e    25  0.423729    b66b5e9a  \n",
       "3       2ac1be019bf73e    52  0.881356    b66b5e9a  \n",
       "4       2ac1be019bf73e    45  0.762712    b66b5e9a  \n",
       "...                ...   ...       ...         ...  \n",
       "143005  d3c351143d72ef    36  0.418605    77eaf8c7  \n",
       "143006  d3c351143d72ef    28  0.325581    77eaf8c7  \n",
       "143007  d3c351143d72ef    10  0.116279    77eaf8c7  \n",
       "143008  d3c351143d72ef    46  0.534884    77eaf8c7  \n",
       "143009  d3c351143d72ef     4  0.046512    77eaf8c7  \n",
       "\n",
       "[143010 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('../raw_data/AI4Code/distilbert_data.csv')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilhanb11/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/codebert-base/tokenizer_config.json',\n",
       " '../models/codebert-base/special_tokens_map.json',\n",
       " '../models/codebert-base/vocab.json',\n",
       " '../models/codebert-base/merges.txt',\n",
       " '../models/codebert-base/added_tokens.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFAutoModel, RobertaTokenizer\n",
    "\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "\n",
    "model = TFAutoModel.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.save_pretrained(BASE_MODEL)\n",
    "tokenizer.save_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccaad41af46491d958ffa57874cbce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: (1679, 128)\n",
      "attention_mask: (1679, 128)\n",
      "labels: (1679,)\n",
      "groups: (1679,)\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask = tokenize(df[\"source\"])\n",
    "\n",
    "labels = df[\"pct_rank\"].to_numpy()\n",
    "groups = df[\"ancestor_id\"].to_numpy()\n",
    "\n",
    "print(\"input_ids:\", input_ids.shape)\n",
    "print(\"attention_mask:\", attention_mask.shape)\n",
    "print(\"labels:\", labels.shape)\n",
    "print(\"groups:\", groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at ../models/codebert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_2 (TFRobertaM  TFBaseModelOutputWi  124645632  ['attention_mask[0][0]',         \n",
      " odel)                          thPoolingAndCrossAt               'input_ids[0][0]']              \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model_2[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            769         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,646,401\n",
      "Trainable params: 124,646,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask, labels, groups = shuffle(\n",
    "    input_ids, attention_mask, labels, groups, random_state=RANDOM_STATE\n",
    ")\n",
    "kfold = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(input_ids, labels, groups=groups)):\n",
    "    if TPU is not None:\n",
    "        tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "\n",
    "    with STRATEGY.scope():\n",
    "        model = get_model()\n",
    "        model.summary()\n",
    "\n",
    "    train_dataset = get_dataset(\n",
    "        input_ids=input_ids[train_index],\n",
    "        attention_mask=attention_mask[train_index],\n",
    "        labels=labels[train_index],\n",
    "        repeated=True,\n",
    "    )\n",
    "    val_dataset = get_dataset(\n",
    "        input_ids=input_ids[val_index],\n",
    "        attention_mask=attention_mask[val_index],\n",
    "        labels=labels[val_index],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        steps_per_epoch=len(train_index) // BATCH_SIZE,\n",
    "        epochs=1,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    model.save_weights(f\"model_{i}.h5\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_ai4_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
