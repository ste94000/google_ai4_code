{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 19:05:48.346077: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-21 19:05:48.351215: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 19:05:48.689597: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 19:05:49.960888: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 19:05:52.539649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from IPython.display import display\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.16.1\n",
      "Using GPU/CPU\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../raw_data/AI4Code\"\n",
    "BASE_MODEL = \"../models/distilbert-base-uncased\"\n",
    "N_SPLITS = 5\n",
    "SEQ_LEN = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "    BATCH_SIZE = 128 * STRATEGY.num_replicas_in_sync\n",
    "except Exception:\n",
    "    TPU = None\n",
    "    STRATEGY = tf.distribute.get_strategy()\n",
    "    BATCH_SIZE = 32\n",
    "    LIMIT = 10_000\n",
    "\n",
    "print(\"TensorFlow\", tf.__version__)\n",
    "\n",
    "if TPU is not None:\n",
    "    print(\"Using TPU v3-8\")\n",
    "else:\n",
    "    print(\"Using GPU/CPU\")\n",
    "\n",
    "print(\"Batch size:\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_notebook(path: str) -> pd.DataFrame:\n",
    "    with open(path) as file:\n",
    "        df = pd.DataFrame(json.load(file))\n",
    "    df[\"id\"] = os.path.splitext(os.path.basename(path))[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_order(row: Tuple[str, str]) -> pd.DataFrame:\n",
    "    cell_ids = row[1].split(\" \")\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": [row[0] for _ in range(len(cell_ids))],\n",
    "            \"cell_id\": cell_ids,\n",
    "            \"rank\": range(len(cell_ids)),\n",
    "        }\n",
    "    )\n",
    "    df[\"pct_rank\"] = df[\"rank\"] / len(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(source: pd.Series) -> Tuple[np.array, np.array]:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(BASE_MODEL, do_lower_case=True)\n",
    "\n",
    "    input_ids = np.zeros((len(source), SEQ_LEN), dtype=\"int32\")\n",
    "    attention_mask = np.zeros((len(source), SEQ_LEN), dtype=\"int32\")\n",
    "\n",
    "    for i, x in enumerate(tqdm(source, total=len(source))):\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            x,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=SEQ_LEN,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        input_ids[i] = encoding[\"input_ids\"]\n",
    "        attention_mask[i] = encoding[\"attention_mask\"]\n",
    "\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(\n",
    "    input_ids: np.array,\n",
    "    attention_mask: np.array,\n",
    "    labels: Optional[np.array] = None,\n",
    "    ordered: bool = False,\n",
    "    repeated: bool = False,\n",
    ") -> tf.data.Dataset:\n",
    "    if labels is not None:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ({\"input_ids\": tf.convert_to_tensor(input_ids), \"attention_mask\": tf.convert_to_tensor(attention_mask)}, labels)\n",
    "        )\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\"input_ids\": tf.convert_to_tensor(input_ids), \"attention_mask\": tf.convert_to_tensor(attention_mask)}\n",
    "        )\n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    if not ordered:\n",
    "        dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> tf.keras.Model:\n",
    "    backbone = transformers.TFDistilBertModel.from_pretrained(BASE_MODEL)\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(SEQ_LEN,),\n",
    "        dtype=tf.int32,\n",
    "        name=\"input_ids\",\n",
    "    )\n",
    "    attention_mask = tf.keras.layers.Input(\n",
    "        shape=(SEQ_LEN,),\n",
    "        dtype=tf.int32,\n",
    "        name=\"attention_mask\",\n",
    "    )\n",
    "    x = backbone(\n",
    "        {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "        },\n",
    "    )\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"linear\", dtype=\"float32\")(x[0][:, 0, :])\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_ids, attention_mask],\n",
    "        outputs=outputs,\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a051a0ee0984db4a68dfa0eb62fce86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de49fd480c3144bca9ceba1f8e88aa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156707</th>\n",
       "      <td>7fafd119</td>\n",
       "      <td># 라이브러리 &amp; 데이터 불러오기</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>75</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>7cc543d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156708</th>\n",
       "      <td>e75ce892</td>\n",
       "      <td>## ❔❓ 제품 배송 시간에 맞춰 배송되었는지 예측모델 만들기</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>109</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>7cc543d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156709</th>\n",
       "      <td>99e99cc4</td>\n",
       "      <td>### 정규화</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>7cc543d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156710</th>\n",
       "      <td>c63df0e4</td>\n",
       "      <td># 💓🐨 연습_02 🐨💓</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>108</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>7cc543d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156711</th>\n",
       "      <td>1c112aaa</td>\n",
       "      <td>## csv 생성 및 확인</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>70</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>7cc543d3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156712 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id                                             source  \\\n",
       "0       58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1       950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2       3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3       99385c1e    #### How did carriers performed over the years?   \n",
       "4       26c65ce6  An average departure delay and its std are slo...   \n",
       "...          ...                                                ...   \n",
       "156707  7fafd119                                 # 라이브러리 & 데이터 불러오기   \n",
       "156708  e75ce892                 ## ❔❓ 제품 배송 시간에 맞춰 배송되었는지 예측모델 만들기   \n",
       "156709  99e99cc4                                            ### 정규화   \n",
       "156710  c63df0e4                                      # 💓🐨 연습_02 🐨💓   \n",
       "156711  1c112aaa                                     ## csv 생성 및 확인   \n",
       "\n",
       "                    id  rank  pct_rank ancestor_id  \n",
       "0       2ac1be019bf73e    26  0.440678    b66b5e9a  \n",
       "1       2ac1be019bf73e    21  0.355932    b66b5e9a  \n",
       "2       2ac1be019bf73e    25  0.423729    b66b5e9a  \n",
       "3       2ac1be019bf73e    52  0.881356    b66b5e9a  \n",
       "4       2ac1be019bf73e    45  0.762712    b66b5e9a  \n",
       "...                ...   ...       ...         ...  \n",
       "156707  ff2cfc75d39200    75  0.669643    7cc543d3  \n",
       "156708  ff2cfc75d39200   109  0.973214    7cc543d3  \n",
       "156709  ff2cfc75d39200   100  0.892857    7cc543d3  \n",
       "156710  ff2cfc75d39200   108  0.964286    7cc543d3  \n",
       "156711  ff2cfc75d39200    70  0.625000    7cc543d3  \n",
       "\n",
       "[156712 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = glob.glob(os.path.join(DATA_PATH, \"train_data\", \"*.json\"))\n",
    "if LIMIT is not None:\n",
    "    paths = paths[:LIMIT]\n",
    "\n",
    "source_df = pd.concat([read_notebook(x) for x in tqdm(paths, total=len(paths))])\n",
    "\n",
    "source_df = source_df[source_df[\"cell_type\"] == \"markdown\"]\n",
    "source_df = source_df.drop(\"cell_type\", axis=1)\n",
    "source_df = source_df.rename_axis(\"cell_id\").reset_index()\n",
    "\n",
    "order_df = pd.read_csv(os.path.join(DATA_PATH, \"train_orders.csv\"), index_col=\"id\")\n",
    "order_df = pd.concat(\n",
    "    [expand_order(row) for row in tqdm(order_df.itertuples(), total=len(order_df))])\n",
    "\n",
    "ancestors_df = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"train_ancestors.csv\"),\n",
    "    usecols=[\"id\", \"ancestor_id\"],\n",
    "    index_col=\"id\")\n",
    "\n",
    "df = source_df.merge(order_df, on=[\"id\", \"cell_id\"]).merge(ancestors_df, on=\"id\")\n",
    "df = df.dropna()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>language</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156707</th>\n",
       "      <td>7fafd119</td>\n",
       "      <td># 라이브러리 &amp; 데이터 불러오기</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>75</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>7cc543d3</td>\n",
       "      <td>en</td>\n",
       "      <td>0.428570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156708</th>\n",
       "      <td>e75ce892</td>\n",
       "      <td>## ❔❓ 제품 배송 시간에 맞춰 배송되었는지 예측모델 만들기</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>109</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>7cc543d3</td>\n",
       "      <td>en</td>\n",
       "      <td>0.428570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156709</th>\n",
       "      <td>99e99cc4</td>\n",
       "      <td>### 정규화</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>100</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>7cc543d3</td>\n",
       "      <td>en</td>\n",
       "      <td>0.428570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156710</th>\n",
       "      <td>c63df0e4</td>\n",
       "      <td># 💓🐨 연습_02 🐨💓</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>108</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>7cc543d3</td>\n",
       "      <td>en</td>\n",
       "      <td>0.428570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156711</th>\n",
       "      <td>1c112aaa</td>\n",
       "      <td>## csv 생성 및 확인</td>\n",
       "      <td>ff2cfc75d39200</td>\n",
       "      <td>70</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>7cc543d3</td>\n",
       "      <td>en</td>\n",
       "      <td>0.428570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156712 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id                                             source  \\\n",
       "0       58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1       950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2       3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3       99385c1e    #### How did carriers performed over the years?   \n",
       "4       26c65ce6  An average departure delay and its std are slo...   \n",
       "...          ...                                                ...   \n",
       "156707  7fafd119                                 # 라이브러리 & 데이터 불러오기   \n",
       "156708  e75ce892                 ## ❔❓ 제품 배송 시간에 맞춰 배송되었는지 예측모델 만들기   \n",
       "156709  99e99cc4                                            ### 정규화   \n",
       "156710  c63df0e4                                      # 💓🐨 연습_02 🐨💓   \n",
       "156711  1c112aaa                                     ## csv 생성 및 확인   \n",
       "\n",
       "                    id  rank  pct_rank ancestor_id language     score  \n",
       "0       2ac1be019bf73e    26  0.440678    b66b5e9a       en  0.999996  \n",
       "1       2ac1be019bf73e    21  0.355932    b66b5e9a       en  0.999996  \n",
       "2       2ac1be019bf73e    25  0.423729    b66b5e9a       en  0.999996  \n",
       "3       2ac1be019bf73e    52  0.881356    b66b5e9a       en  0.999996  \n",
       "4       2ac1be019bf73e    45  0.762712    b66b5e9a       en  0.999996  \n",
       "...                ...   ...       ...         ...      ...       ...  \n",
       "156707  ff2cfc75d39200    75  0.669643    7cc543d3       en  0.428570  \n",
       "156708  ff2cfc75d39200   109  0.973214    7cc543d3       en  0.428570  \n",
       "156709  ff2cfc75d39200   100  0.892857    7cc543d3       en  0.428570  \n",
       "156710  ff2cfc75d39200   108  0.964286    7cc543d3       en  0.428570  \n",
       "156711  ff2cfc75d39200    70  0.625000    7cc543d3       en  0.428570  \n",
       "\n",
       "[156712 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_df = pd.read_csv('../raw_data/AI4Code/all_languages.csv')\n",
    "merged_df = df.merge(lang_df, on='id', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>language</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156679</th>\n",
       "      <td>d5e9c516</td>\n",
       "      <td># Optimization</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>36</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>77eaf8c7</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156680</th>\n",
       "      <td>47fd56dd</td>\n",
       "      <td># Optimizer Analytics</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>28</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>77eaf8c7</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156681</th>\n",
       "      <td>a3bdddf7</td>\n",
       "      <td># Define Constraints</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>77eaf8c7</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156682</th>\n",
       "      <td>67b26d0c</td>\n",
       "      <td>In validation RMS 99.4 and Adam 66.4 this crea...</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>46</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>77eaf8c7</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156683</th>\n",
       "      <td>c0bb4fbe</td>\n",
       "      <td># Loading data from file</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>4</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>77eaf8c7</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143010 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id                                             source  \\\n",
       "0       58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1       950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2       3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3       99385c1e    #### How did carriers performed over the years?   \n",
       "4       26c65ce6  An average departure delay and its std are slo...   \n",
       "...          ...                                                ...   \n",
       "156679  d5e9c516                                     # Optimization   \n",
       "156680  47fd56dd                              # Optimizer Analytics   \n",
       "156681  a3bdddf7                               # Define Constraints   \n",
       "156682  67b26d0c  In validation RMS 99.4 and Adam 66.4 this crea...   \n",
       "156683  c0bb4fbe                           # Loading data from file   \n",
       "\n",
       "                    id  rank  pct_rank ancestor_id language     score  \n",
       "0       2ac1be019bf73e    26  0.440678    b66b5e9a       en  0.999996  \n",
       "1       2ac1be019bf73e    21  0.355932    b66b5e9a       en  0.999996  \n",
       "2       2ac1be019bf73e    25  0.423729    b66b5e9a       en  0.999996  \n",
       "3       2ac1be019bf73e    52  0.881356    b66b5e9a       en  0.999996  \n",
       "4       2ac1be019bf73e    45  0.762712    b66b5e9a       en  0.999996  \n",
       "...                ...   ...       ...         ...      ...       ...  \n",
       "156679  d3c351143d72ef    36  0.418605    77eaf8c7       en  0.999995  \n",
       "156680  d3c351143d72ef    28  0.325581    77eaf8c7       en  0.999995  \n",
       "156681  d3c351143d72ef    10  0.116279    77eaf8c7       en  0.999995  \n",
       "156682  d3c351143d72ef    46  0.534884    77eaf8c7       en  0.999995  \n",
       "156683  d3c351143d72ef     4  0.046512    77eaf8c7       en  0.999995  \n",
       "\n",
       "[143010 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merged_df[merged_df['score'] >= 0.75]\n",
    "merged_df = merged_df[merged_df['language'] == 'en']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['language', 'score'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m merged_df\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['language', 'score'] not found in axis\""
     ]
    }
   ],
   "source": [
    "merged_df = merged_df.drop(columns=['language', 'score'])\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DATA_PATH, \"merged_data.csv\")\n",
    "merged_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143005</th>\n",
       "      <td>d5e9c516</td>\n",
       "      <td># Optimization</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>36</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143006</th>\n",
       "      <td>47fd56dd</td>\n",
       "      <td># Optimizer Analytics</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>28</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143007</th>\n",
       "      <td>a3bdddf7</td>\n",
       "      <td># Define Constraints</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143008</th>\n",
       "      <td>67b26d0c</td>\n",
       "      <td>In validation RMS 99.4 and Adam 66.4 this crea...</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>46</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143009</th>\n",
       "      <td>c0bb4fbe</td>\n",
       "      <td># Loading data from file</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>4</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143010 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id                                             source  \\\n",
       "0       58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1       950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2       3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3       99385c1e    #### How did carriers performed over the years?   \n",
       "4       26c65ce6  An average departure delay and its std are slo...   \n",
       "...          ...                                                ...   \n",
       "143005  d5e9c516                                     # Optimization   \n",
       "143006  47fd56dd                              # Optimizer Analytics   \n",
       "143007  a3bdddf7                               # Define Constraints   \n",
       "143008  67b26d0c  In validation RMS 99.4 and Adam 66.4 this crea...   \n",
       "143009  c0bb4fbe                           # Loading data from file   \n",
       "\n",
       "                    id  rank  pct_rank ancestor_id  \n",
       "0       2ac1be019bf73e    26  0.440678    b66b5e9a  \n",
       "1       2ac1be019bf73e    21  0.355932    b66b5e9a  \n",
       "2       2ac1be019bf73e    25  0.423729    b66b5e9a  \n",
       "3       2ac1be019bf73e    52  0.881356    b66b5e9a  \n",
       "4       2ac1be019bf73e    45  0.762712    b66b5e9a  \n",
       "...                ...   ...       ...         ...  \n",
       "143005  d3c351143d72ef    36  0.418605    77eaf8c7  \n",
       "143006  d3c351143d72ef    28  0.325581    77eaf8c7  \n",
       "143007  d3c351143d72ef    10  0.116279    77eaf8c7  \n",
       "143008  d3c351143d72ef    46  0.534884    77eaf8c7  \n",
       "143009  d3c351143d72ef     4  0.046512    77eaf8c7  \n",
       "\n",
       "[143010 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('../raw_data/AI4Code/merged_data.csv')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/distilbert-base-uncased/tokenizer_config.json',\n",
       " '../models/distilbert-base-uncased/special_tokens_map.json',\n",
       " '../models/distilbert-base-uncased/vocab.txt',\n",
       " '../models/distilbert-base-uncased/added_tokens.json',\n",
       " '../models/distilbert-base-uncased/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "model = TFAutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "BASE_MODEL = \"../models/distilbert-base-uncased\"\n",
    "model.save_pretrained(BASE_MODEL)\n",
    "tokenizer.save_pretrained(BASE_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c5d7c03aef4aeeb1fc4c907e69f3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: (143010, 128)\n",
      "attention_mask: (143010, 128)\n",
      "labels: (143010,)\n",
      "groups: (143010,)\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask = tokenize(merged_df[\"source\"])\n",
    "\n",
    "labels = merged_df[\"pct_rank\"].to_numpy()\n",
    "groups = merged_df[\"ancestor_id\"].to_numpy()\n",
    "\n",
    "print(\"input_ids:\", input_ids.shape)\n",
    "print(\"attention_mask:\", attention_mask.shape)\n",
    "print(\"labels:\", labels.shape)\n",
    "print(\"groups:\", groups.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertModel.\n",
      "\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at ../models/distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'tf_distil_bert_model_5' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_distil_bert_model_5' (type TFDistilBertModel):\n  • input_ids={'input_ids': '<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=input_ids>', 'attention_mask': '<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=attention_mask>'}\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mtpu\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39minitialize_tpu_system(TPU)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m STRATEGY\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m---> 11\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     14\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m get_dataset(\n\u001b[1;32m     15\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids[train_index],\n\u001b[1;32m     16\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask[train_index],\n\u001b[1;32m     17\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels[train_index],\n\u001b[1;32m     18\u001b[0m     repeated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m )\n",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(\n\u001b[1;32m      4\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(SEQ_LEN,),\n\u001b[1;32m      5\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m      6\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(\n\u001b[1;32m      9\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(SEQ_LEN,),\n\u001b[1;32m     10\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32,\n\u001b[1;32m     11\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, :])\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(\n\u001b[1;32m     22\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[input_ids, attention_mask],\n\u001b[1;32m     23\u001b[0m     outputs\u001b[38;5;241m=\u001b[39moutputs,\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:436\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 436\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:561\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(main_input) \u001b[38;5;129;01mor\u001b[39;00m main_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'tf_distil_bert_model_5' (type TFDistilBertModel).\n\nData of type <class 'keras.src.backend.common.keras_tensor.KerasTensor'> is not allowed only (<class 'tensorflow.python.framework.tensor.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>) is accepted for input_ids.\n\nCall arguments received by layer 'tf_distil_bert_model_5' (type TFDistilBertModel):\n  • input_ids={'input_ids': '<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=input_ids>', 'attention_mask': '<KerasTensor shape=(None, 128), dtype=int32, sparse=None, name=attention_mask>'}\n  • attention_mask=None\n  • head_mask=None\n  • inputs_embeds=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask, labels, groups = shuffle(\n",
    "    input_ids, attention_mask, labels, groups, random_state=RANDOM_STATE\n",
    ")\n",
    "kfold = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(input_ids, labels, groups=groups)):\n",
    "    if TPU is not None:\n",
    "        tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "\n",
    "    with STRATEGY.scope():\n",
    "        model = get_model()\n",
    "        model.summary()\n",
    "\n",
    "    train_dataset = get_dataset(\n",
    "        input_ids=input_ids[train_index],\n",
    "        attention_mask=attention_mask[train_index],\n",
    "        labels=labels[train_index],\n",
    "        repeated=True,\n",
    "    )\n",
    "    val_dataset = get_dataset(\n",
    "        input_ids=input_ids[val_index],\n",
    "        attention_mask=attention_mask[val_index],\n",
    "        labels=labels[val_index],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        steps_per_epoch=len(train_index) // BATCH_SIZE,\n",
    "        epochs=1,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    model.save_weights(f\"model_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_ai4_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
