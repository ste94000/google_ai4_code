{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 16:39:46.038856: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-22 16:39:46.173624: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-22 16:39:46.178263: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-22 16:39:46.178284: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-06-22 16:39:47.083693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-06-22 16:39:47.083799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-06-22 16:39:47.083805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from IPython.display import display\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.11.0\n",
      "Using GPU/CPU\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../raw_data/AI4Code\"\n",
    "BASE_MODEL = \"../models/distilbert-base-uncased\"\n",
    "N_SPLITS = 5\n",
    "SEQ_LEN = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "    BATCH_SIZE = 128 * STRATEGY.num_replicas_in_sync\n",
    "except Exception:\n",
    "    TPU = None\n",
    "    STRATEGY = tf.distribute.get_strategy()\n",
    "    BATCH_SIZE = 32\n",
    "    LIMIT = 10_000\n",
    "\n",
    "print(\"TensorFlow\", tf.__version__)\n",
    "\n",
    "if TPU is not None:\n",
    "    print(\"Using TPU v3-8\")\n",
    "else:\n",
    "    print(\"Using GPU/CPU\")\n",
    "\n",
    "print(\"Batch size:\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_notebook(path: str) -> pd.DataFrame:\n",
    "    with open(path) as file:\n",
    "        df = pd.DataFrame(json.load(file))\n",
    "    df[\"id\"] = os.path.splitext(os.path.basename(path))[0]\n",
    "    return df\n",
    "\n",
    "def expand_order(row: Tuple[str, str]) -> pd.DataFrame:\n",
    "    cell_ids = row[1].split(\" \")\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": [row[0] for _ in range(len(cell_ids))],\n",
    "            \"cell_id\": cell_ids,\n",
    "            \"rank\": range(len(cell_ids)),\n",
    "        }\n",
    "    )\n",
    "    df[\"pct_rank\"] = df[\"rank\"] / len(df)\n",
    "    return df\n",
    "\n",
    "def tokenize(source: pd.Series) -> Tuple[np.array, np.array]:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(BASE_MODEL, do_lower_case=True)\n",
    "\n",
    "    input_ids = np.zeros((len(source), SEQ_LEN), dtype=\"int32\")\n",
    "    attention_mask = np.zeros((len(source), SEQ_LEN), dtype=\"int32\")\n",
    "\n",
    "    for i, x in enumerate(tqdm(source, total=len(source))):\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            x,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=SEQ_LEN,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        input_ids[i] = encoding[\"input_ids\"]\n",
    "        attention_mask[i] = encoding[\"attention_mask\"]\n",
    "\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def get_dataset(\n",
    "    input_ids: np.array,\n",
    "    attention_mask: np.array,\n",
    "    labels: Optional[np.array] = None,\n",
    "    ordered: bool = False,\n",
    "    repeated: bool = False,\n",
    ") -> tf.data.Dataset:\n",
    "    if labels is not None:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ({\"input_ids\": input_ids, \"attention_mask\": attention_mask}, labels)\n",
    "        )\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "        )\n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    if not ordered:\n",
    "        dataset = dataset.shuffle(1024)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def get_model() -> tf.keras.Model:\n",
    "    backbone = transformers.TFDistilBertModel.from_pretrained(BASE_MODEL)\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(SEQ_LEN,),\n",
    "        dtype=tf.int32,\n",
    "        name=\"input_ids\",\n",
    "    )\n",
    "    attention_mask = tf.keras.layers.Input(\n",
    "        shape=(SEQ_LEN,),\n",
    "        dtype=tf.int32,\n",
    "        name=\"attention_mask\",\n",
    "    )\n",
    "    x = backbone(\n",
    "        {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "        },\n",
    "    )\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"linear\", dtype=\"float32\")(x[0][:, 0, :])\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_ids, attention_mask],\n",
    "        outputs=outputs,\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8c2f766ec14d82951675a7ca00a545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec139e585e044aa0affc57dae43ae8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156679</th>\n",
       "      <td>d5e9c516</td>\n",
       "      <td># Optimization</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>36</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156680</th>\n",
       "      <td>47fd56dd</td>\n",
       "      <td># Optimizer Analytics</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>28</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156681</th>\n",
       "      <td>a3bdddf7</td>\n",
       "      <td># Define Constraints</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156682</th>\n",
       "      <td>67b26d0c</td>\n",
       "      <td>In validation RMS 99.4 and Adam 66.4 this crea...</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>46</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156683</th>\n",
       "      <td>c0bb4fbe</td>\n",
       "      <td># Loading data from file</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>4</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143010 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id                                             source  \\\n",
       "0       58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1       950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2       3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3       99385c1e    #### How did carriers performed over the years?   \n",
       "4       26c65ce6  An average departure delay and its std are slo...   \n",
       "...          ...                                                ...   \n",
       "156679  d5e9c516                                     # Optimization   \n",
       "156680  47fd56dd                              # Optimizer Analytics   \n",
       "156681  a3bdddf7                               # Define Constraints   \n",
       "156682  67b26d0c  In validation RMS 99.4 and Adam 66.4 this crea...   \n",
       "156683  c0bb4fbe                           # Loading data from file   \n",
       "\n",
       "                    id  rank  pct_rank ancestor_id  \n",
       "0       2ac1be019bf73e    26  0.440678    b66b5e9a  \n",
       "1       2ac1be019bf73e    21  0.355932    b66b5e9a  \n",
       "2       2ac1be019bf73e    25  0.423729    b66b5e9a  \n",
       "3       2ac1be019bf73e    52  0.881356    b66b5e9a  \n",
       "4       2ac1be019bf73e    45  0.762712    b66b5e9a  \n",
       "...                ...   ...       ...         ...  \n",
       "156679  d3c351143d72ef    36  0.418605    77eaf8c7  \n",
       "156680  d3c351143d72ef    28  0.325581    77eaf8c7  \n",
       "156681  d3c351143d72ef    10  0.116279    77eaf8c7  \n",
       "156682  d3c351143d72ef    46  0.534884    77eaf8c7  \n",
       "156683  d3c351143d72ef     4  0.046512    77eaf8c7  \n",
       "\n",
       "[143010 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = glob.glob(os.path.join(DATA_PATH, \"train_data\", \"*.json\"))\n",
    "if LIMIT is not None:\n",
    "    paths = paths[:LIMIT]\n",
    "\n",
    "source_df = pd.concat([read_notebook(x) for x in tqdm(paths, total=len(paths))])\n",
    "\n",
    "source_df = source_df[source_df[\"cell_type\"] == \"markdown\"]\n",
    "source_df = source_df.drop(\"cell_type\", axis=1)\n",
    "source_df = source_df.rename_axis(\"cell_id\").reset_index()\n",
    "\n",
    "order_df = pd.read_csv(os.path.join(DATA_PATH, \"train_orders.csv\"), index_col=\"id\")\n",
    "order_df = pd.concat(\n",
    "    [expand_order(row) for row in tqdm(order_df.itertuples(), total=len(order_df))]\n",
    ")\n",
    "\n",
    "ancestors_df = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"train_ancestors.csv\"),\n",
    "    usecols=[\"id\", \"ancestor_id\"],\n",
    "    index_col=\"id\",\n",
    ")\n",
    "\n",
    "df = source_df.merge(order_df, on=[\"id\", \"cell_id\"]).merge(ancestors_df, on=\"id\")\n",
    "df = df.dropna()\n",
    "\n",
    "lang_df = pd.read_csv('../raw_data/AI4Code/all_languages.csv')\n",
    "merged_df = df.merge(lang_df, on='id', how='left')\n",
    "merged_df = merged_df[merged_df['score'] >= 0.75]\n",
    "merged_df = merged_df[merged_df['language'] == 'en']\n",
    "df = merged_df.drop(columns=['language', 'score'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DATA_PATH, \"distilbert_data.csv\")\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58900633</td>\n",
       "      <td>#### Explore airports\\nThere are 268 unique ai...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>26</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950a8058</td>\n",
       "      <td>#### Airlines\\nAfter looking into delay distri...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>21</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d3eb7f6</td>\n",
       "      <td>Distribution of airlines is extremely right sk...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>25</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99385c1e</td>\n",
       "      <td>#### How did carriers performed over the years?</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>52</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26c65ce6</td>\n",
       "      <td>An average departure delay and its std are slo...</td>\n",
       "      <td>2ac1be019bf73e</td>\n",
       "      <td>45</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>b66b5e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143005</th>\n",
       "      <td>d5e9c516</td>\n",
       "      <td># Optimization</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>36</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143006</th>\n",
       "      <td>47fd56dd</td>\n",
       "      <td># Optimizer Analytics</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>28</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143007</th>\n",
       "      <td>a3bdddf7</td>\n",
       "      <td># Define Constraints</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143008</th>\n",
       "      <td>67b26d0c</td>\n",
       "      <td>In validation RMS 99.4 and Adam 66.4 this crea...</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>46</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143009</th>\n",
       "      <td>c0bb4fbe</td>\n",
       "      <td># Loading data from file</td>\n",
       "      <td>d3c351143d72ef</td>\n",
       "      <td>4</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>77eaf8c7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143010 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_id                                             source  \\\n",
       "0       58900633  #### Explore airports\\nThere are 268 unique ai...   \n",
       "1       950a8058  #### Airlines\\nAfter looking into delay distri...   \n",
       "2       3d3eb7f6  Distribution of airlines is extremely right sk...   \n",
       "3       99385c1e    #### How did carriers performed over the years?   \n",
       "4       26c65ce6  An average departure delay and its std are slo...   \n",
       "...          ...                                                ...   \n",
       "143005  d5e9c516                                     # Optimization   \n",
       "143006  47fd56dd                              # Optimizer Analytics   \n",
       "143007  a3bdddf7                               # Define Constraints   \n",
       "143008  67b26d0c  In validation RMS 99.4 and Adam 66.4 this crea...   \n",
       "143009  c0bb4fbe                           # Loading data from file   \n",
       "\n",
       "                    id  rank  pct_rank ancestor_id  \n",
       "0       2ac1be019bf73e    26  0.440678    b66b5e9a  \n",
       "1       2ac1be019bf73e    21  0.355932    b66b5e9a  \n",
       "2       2ac1be019bf73e    25  0.423729    b66b5e9a  \n",
       "3       2ac1be019bf73e    52  0.881356    b66b5e9a  \n",
       "4       2ac1be019bf73e    45  0.762712    b66b5e9a  \n",
       "...                ...   ...       ...         ...  \n",
       "143005  d3c351143d72ef    36  0.418605    77eaf8c7  \n",
       "143006  d3c351143d72ef    28  0.325581    77eaf8c7  \n",
       "143007  d3c351143d72ef    10  0.116279    77eaf8c7  \n",
       "143008  d3c351143d72ef    46  0.534884    77eaf8c7  \n",
       "143009  d3c351143d72ef     4  0.046512    77eaf8c7  \n",
       "\n",
       "[143010 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../raw_data/AI4Code/distilbert_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilhanb11/.pyenv/versions/3.10.6/envs/google_ai4_code/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-06-22 15:32:25.133334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-06-22 15:32:25.133725: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-06-22 15:32:25.133807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (AYO-LP-BILH): /proc/driver/nvidia/version does not exist\n",
      "2024-06-22 15:32:25.135428: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/distilbert-base-uncased/tokenizer_config.json',\n",
       " '../models/distilbert-base-uncased/special_tokens_map.json',\n",
       " '../models/distilbert-base-uncased/vocab.txt',\n",
       " '../models/distilbert-base-uncased/added_tokens.json',\n",
       " '../models/distilbert-base-uncased/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "model = TFAutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.save_pretrained(BASE_MODEL)\n",
    "tokenizer.save_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a089f04c93f4a918a2a97bb74b37e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: (240, 128)\n",
      "attention_mask: (240, 128)\n",
      "labels: (240,)\n",
      "groups: (240,)\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask = tokenize(df[\"source\"])\n",
    "\n",
    "labels = df[\"pct_rank\"].to_numpy()\n",
    "groups = df[\"ancestor_id\"].to_numpy()\n",
    "\n",
    "print(\"input_ids:\", input_ids.shape)\n",
    "print(\"attention_mask:\", attention_mask.shape)\n",
    "print(\"labels:\", labels.shape)\n",
    "print(\"groups:\", groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertModel.\n",
      "\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at ../models/distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_distil_bert_model_2 (TFDist  TFBaseModelOutput(l  66362880   ['attention_mask[0][0]',         \n",
      " ilBertModel)                   ast_hidden_state=(N               'input_ids[0][0]']              \n",
      "                                one, 128, 768),                                                   \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_distil_bert_model_2[0][0]'] \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            769         ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,363,649\n",
      "Trainable params: 66,363,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "5/5 - 42s - loss: 0.2458 - val_loss: 0.1432 - 42s/epoch - 8s/step\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask, labels, groups = shuffle(\n",
    "    input_ids, attention_mask, labels, groups, random_state=RANDOM_STATE\n",
    ")\n",
    "kfold = GroupKFold(n_splits=N_SPLITS)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(input_ids, labels, groups=groups)):\n",
    "    if TPU is not None:\n",
    "        tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "\n",
    "    with STRATEGY.scope():\n",
    "        model = get_model()\n",
    "        model.summary()\n",
    "\n",
    "    train_dataset = get_dataset(\n",
    "        input_ids=input_ids[train_index],\n",
    "        attention_mask=attention_mask[train_index],\n",
    "        labels=labels[train_index],\n",
    "        repeated=True,\n",
    "    )\n",
    "    val_dataset = get_dataset(\n",
    "        input_ids=input_ids[val_index],\n",
    "        attention_mask=attention_mask[val_index],\n",
    "        labels=labels[val_index],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        steps_per_epoch=len(train_index) // BATCH_SIZE,\n",
    "        epochs=1,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    model.save_weights(f\"model_{i}.h5\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_data': None,\n",
       " 'model': <keras.engine.functional.Functional at 0x7fa1e5445c00>,\n",
       " '_chief_worker_only': None,\n",
       " '_supports_tf_logs': False,\n",
       " 'history': {'loss': [0.24577596783638], 'val_loss': [0.14320646226406097]},\n",
       " 'params': {'verbose': 2, 'epochs': 1, 'steps': 5},\n",
       " 'epoch': [0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google_ai4_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
